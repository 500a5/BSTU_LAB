### К Экзамену

#### Л.р. № 1 (Алгоритм отжига)



#### Л.р. № 2 (Алгоритм теории адаптивного резонанса)

Человеческий мозг изучает новые понятия, сравнивая с уже существующими знаниями. Если новое понятие человеку не удается осмыслить, то он создает новую структуру для понимания явления, которое выходит за рамки существующей структуры. Впоследствии эта новая структура может стать основой для усвоения другой информации.

**Параметры алгоритма:**

<img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210110232026760.png" alt="image-20210110232026760" style="zoom:80%;" />побитовый И – вектор, представляющий собой результат побитового И для двух векторов, в итоге получается новый вектор;

<img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210110232056664.png" alt="image-20210110232056664" style="zoom:80%;" />значимость вектора, то есть количество разрядов в векторе, которые не равны нулю;

N – количество векторов – прототипов, то есть максимальное число кластеров, которое может поддерживаться;
(0<ρ<=1) - параметр внимательности
P – вектор – прототип;
E – вектор признаков;
d - размер вектора;
β - бета- параметр, равный небольшому целому числу.

Вектор признаков - группа значений в двоичном коде.
Вектор–прототип - 
Кластер - классификации данных в отдельные сегменты.

##### Алгоритм

1. Создается первый *вектор–прототип* из первого вектора признаков

    (Изначально не существует ни одного вектора–прототипа) 

2. Проверяются на схожесть все последующие векторы признаков с *вектором-прототипом*. 

   Целью проверки является выяснение схожести вектора признаков и текущего вектора–прототипа, причем значения i меняются от 1 до N. 

   Проверка на схожесть определяется решением уравнения:    <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210110214758375.png" alt="image-20210110214758375" style="zoom:80%;" />

3. Если тест на внимательность (схожесть) **прошел успешно**:

   Вектор признаков и *вектор-прототип* сравнивается с параметром внимательности (**процесс обучения**):<img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210110215007803.png" alt="image-20210110215007803" style="zoom:80%;" />

4. Если тест на внимательность (схожесть) **не был пройден**, проверяется следующий *вектор-прототип*. 

5. Если все *векторы-прототипы* были проверены, и при этом вектор признаков не был помещен в кластер, то создается новый вектор-прототип из вектора признаков.  
   Это приводит к формированию нового кластера, так как рассматриваемый вектор признаков не соответствует ни одному существующему кластеру. 

6. Если тест на внимательность  (схожесть)  **пройден**, то алгоритм добавляет текущий вектор признаков в текущий *вектор–прототип*. 
   Этот процесс представляет собой простое слияние вектора признаков и вектора прототипа с помощью операции:  <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210110220114077.png" alt="image-20210110220114077" style="zoom:67%;" />

7. В завершении работы алгоритм заново проходит через все вектора признаков и сравнивает их со всеми *векторами-прототипами*. 

**Достоинства**

Оптимизация. Она осуществляется путем изменения значений трех важных параметров алгоритма: 

1. Максимально допустимого количества кластеров .

2. Бета - параметра.
3. Параметра внимательности. 

Максимально допустимое количество кластеров должно быть достаточно большим, чтобы алгоритм при необходимости мог создать новый кластер. 

Бета - параметр и параметр внимательности важны для правильной ориентации алгоритма ART1.

**Недостатки**

Конечный набор кластеров (и векторов-прототипов) может изменяться в зависимости от порядка, в котором проводилось обучение.

**Применения этого алгоритма**

Рекомендации книг для чтения. 
·    статистика;
·    распознавании образов;
·    уменьшении диапазона поиска;
·    поиске в сети Internet;
·    биология.

#### Л.р. № 3 (Муравьиный алгоритм)

Алгоритм основан на специфических свойствах, использующих муравьями для ориентации в пространстве. 

Алгоритм можно использовать для решения не только статичных, но и динамических проблем.

Путь Гамильтона - путь по которому муравей посетил каждый узел только один раз.

**Алгоритм**

1. **Для первого прохода уравнение выбора пути игнорируется.**
   Муравей определяет грань пути по формуле: <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111003021060.png" alt="image-20210111003021060" style="zoom:80%;" />

   t(r,u) - интенсивность фермента на грани между узлами r и u
   h(r,u) -функция, которая представляет измерение обратного расстояния для грани
   a - вес фермента.
   b - коэффициент эвристики. (расстояние между узлами).
   k - грани, которые еще не были посещены.
   r - коэффициент испарения феромона.

   После завершения длина пути может быть подсчитана - она равна сумме всех граней, по которым путешествовал муравей. 

2. Рассчитывается количество фермента оставленного на пути для муравья k: <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111003829791.png" alt="image-20210111003829791" style="zoom:80%;" />
   Короткий путь характеризуется высокой концентрацией фермента, а более длинный путь - более низкой. 

3. Рассчитывается количество фермента, которое будет применено: <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111004120049.png" alt="image-20210111004120049" style="zoom:80%;" />

   Каждая грань помечается ферментом пропорционально длине пути.

4. Чтобы постепенно удалить грани, которые входят в худшие пути в сети, ко всем граням применяется процедура испарения фермента: <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111004447325.png" alt="image-20210111004447325" style="zoom:80%;" />

5. После того как путь муравья завершен, грани обновлены в соответствии с длиной пути и произошло испарение фермента на всех гранях, **алгоритм запускается повторно**. Список табу очищается, и длина пути обнуляется. Муравьям разрешается перемещаться по сети, основывая выбор грани на уравнении 1.1

   Этот процесс может выполняться для постоянного количества путей или до момента, когда на протяжении нескольких запусков не было отмечено повторных изменений. Затем определяется лучший путь, который и является решением.

#### Л.р. № 4 (Введение в искусственные нейронные сети)

Нервная система и мозг человека состоят из **нейронов** (клеток), соединенных между **собой нервными волокнами**. 

**Искусственная нейронная сеть** – математическая модель, а также её программное или аппаратное воплощение, *построенная по принципу* организации и функционирования *биологических нейронных сетей.*

Задачи распознавания образов - дискретные аналоги задач поиска оптимальных решений.
Например: понимание естественного языка, символьная обработка алгебраических выражений, экспертных системах и др. 

В общем случае, любую задачу можно рассматривать как распознавание образа – при известных исходных данных за счет использования определенного алгоритма (методики) требуется получить решение (образ).

Задачи прогнозирования поведения объектов или развития ситуации:

1. Техническая и медицинской диагностики
2. Геологическое прогнозирование
3. Прогнозирования свойств химических соединений, сплавов и новых материалов
4. Прогнозирование урожая и хода строительства крупных объектов
5. Обнаружения лесных пожаров
6. Управления производственными процессами и т.д. 

Обучение сети - определение набора связей и коэффициентов связей между нейронами.

<img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111035329368.png" alt="image-20210111035329368" style="zoom:0%;" />



**Алгоритм обратного распространения ошибки**

Алгоритм позволяет подключать нейронные сети состоящие из нескольких слоев.

В зависимости от задачи, кол-во выходных нейронов соответствует классы распознаваемых образов.
Количество входных нейронов соответствует конфигурации одного изображения.

Весовые коэффициенты делаем нулевыми или задаем им значения [0;0.5] случайным образом.

1. Формируем обучающую выборку M = (X1; Y1)

2. Для каждой пары из М рассчитываем прямое распространение для каждого вектора входного сигнала (X1).

   Расчёт: 

   ​	Для каждого нейрона вычисляем сумму сигналов (Х) и весов w: S_i = sum (x_i * w_i). 
   ​	Получив сумма рассчитываем выход конкретного нейрона y_j = f (S_i). 
   ​	Значение этой функции будет в диапазоне [0;1]

3. Полученную реакцию нейронной сети сравниваем с вектором который должен быть получен в идеале (Y1)

4. Рассчитываем ошибки <img src="C:\Users\Владислав\AppData\Roaming\Typora\typora-user-images\image-20210111054529013.png" alt="image-20210111054529013" style="zoom:80%;" />: ожидаемое выходное значение - полученное

5. Рассчитываем **величину**, на которую нужно скорректировать вес связи соединяющий нейрон скрытого и выходного слоя:
   Производная от функции активации * ошибку: f`(x) = f(x)(1-f(x)) 

6. Получив величину **корректируем сами весовые коэффициенты** этой связи:

   Старый вес * коэф. обучения * величину * выход нейрона скрытого слоя

7. Рассчитываем **величину**, на которую нужно скорректировать вес связи соединяющий нейрон входного и скрытого слоя: 

   Производная от функции активации нейрона скрытого слоя * сумму величин из п.5, умноженных на полученные веса из п.6

8. Получив величину **корректируем сами весовые коэффициенты** этой связи:

   Старый вес * коэф. обучения * величину * выход нейрона входного слоя

Сеть обучается либо по количеству эпох либо по времени либо до нахождения приемлемого результата. 



#### Л.р. № 5 (Решение оптимизационных задач эволюционно-генетическими алгоритмами)

Алгоритм основан не на улучшении конкретного решения, а на поиске лучшего, на множестве решений.
Алгоритм относится к эвристическим алгоритмам.

**Алгоритм**

1. Создание начальной популяции.
2. Вычисление функции приспособленности для особей популяции (оценивание)

Начало цикла:

3. Выбор индивидов из текущей популяции (селекции)
4. Скрещивание и\или мутация
5. Вычисление функций приспособленности для всех особей 
6. Формирование нового поколения 
7. Если выполняются поставленные критерии, то 

Конец цикла
иначе Начало цикла